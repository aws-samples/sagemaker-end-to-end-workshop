{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Workshop\n",
    "## _**Introduction**_\n",
    "\n",
    "This workshop has been adapted from an [AWS blog post](https://aws.amazon.com/blogs/ai/predicting-customer-churn-with-amazon-machine-learning/). \n",
    "\n",
    "Losing customers is costly for any business. Identifying unhappy customers early on gives you a chance to offer them incentives to stay.  In this workshop we'll use machine learning (ML) for automated identification of unhappy customers, also known as customer churn prediction.\n",
    "\n",
    "---\n",
    "In this workshop we will use Gradient Boosted Trees to Predict Mobile Customer Departure.\n",
    "\n",
    "To solve put our model in production we will use some features of SageMaker like:\n",
    "\n",
    "* [Amazon SageMaker Studio](https://docs.aws.amazon.com/sagemaker/latest/dg/studio.html)\n",
    "* [Amazon SageMaker Training Jobs](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html)\n",
    "* [Amazon SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html)\n",
    "  * Manage multiple trials\n",
    "  * Experiment with hyperparameters and charting\n",
    "* [Amazon SageMaker Debugger](https://docs.aws.amazon.com/sagemaker/latest/dg/train-debugger.html)\n",
    "  * Debug your model \n",
    "* [Amazon SageMaker Clarify](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-fairness-and-explainability.html)\n",
    "* [Model hosting](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-deployment.html)\n",
    "  * Set up a persistent endpoint to get predictions from your model\n",
    "* [SageMaker Model Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-model-monitor.html)\n",
    "  * Monitor the quality of your model\n",
    "  * Set alerts for when model quality deviates\n",
    "* [Amazon SageMaker Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines.html)\n",
    "\n",
    "---\n",
    "\n",
    "## The format of this workshop\n",
    "\n",
    "Although we recommend that you follow and run the Labs in order, _this workshop was built in a way that you can skip labs or just do those that interest you the most_ (e.g. you can just run the last Lab, or just run labs 4 an 5, or lab 1 and 4, etc.). Running the labs in order help us understand the natural flow of an ML project and may make more sense.\n",
    "\n",
    "> This is only possible because we leverage the design of SageMaker where each component is independent from each other (e.g. training jobs, hosting, processing) and customers have the freedom to use those that fit better to their use-case.\n",
    "\n",
    "This `0-Introduction` lab is the only Lab that is strictly required to setup some basic things like creating S3 buckets, installing packages, etc.)\n",
    "\n",
    "---\n",
    "\n",
    "## The Data\n",
    "\n",
    "Mobile operators have historical records that tell them which customers ended up churning and which continued using the service. We can use this historical information to train an ML model that can predict customer churn. After training the model, we can pass the profile information of an arbitrary customer (the same profile information that we used to train the model) to the model to have the model predict whether this customer will churn. \n",
    "\n",
    "The dataset we use is publicly available and was mentioned in [Discovering Knowledge in Data](https://www.amazon.com/dp/0470908742/) by Daniel T. Larose. It is attributed by the author to the University of California Irvine Repository of Machine Learning Datasets. The `Data sets` folder that came with this notebook contains the churn dataset.\n",
    "\n",
    "The dataset can be [downloaded here.](https://bcs.wiley.com/he-bcs/Books?action=resource&bcsId=11704&itemId=0470908742&resourceId=46577)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's configure our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install sagemaker==2.42.0 -U\n",
    "!{sys.executable} -m pip install sagemaker-experiments\n",
    "!{sys.executable} -m pip install xgboost==1.3.3\n",
    "#!pip freeze | grep sagemaker\n",
    "#!pip freeze | grep xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sess = boto3.Session()\n",
    "region = sess.region_name\n",
    "sm = sess.client('sagemaker')\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "region = sess.region_name\n",
    "account_id = sess.client('sts', region_name=region).get_caller_identity()[\"Account\"]\n",
    "bucket = 'sagemaker-studio-{}-{}'.format(sess.region_name, account_id)\n",
    "prefix = 'xgboost-churn'\n",
    "\n",
    "try:\n",
    "    if sess.region_name == \"us-east-1\":\n",
    "        sess.client('s3').create_bucket(Bucket=bucket)\n",
    "    else:\n",
    "        sess.client('s3').create_bucket(Bucket=bucket, \n",
    "                                        CreateBucketConfiguration={'LocationConstraint': sess.region_name})\n",
    "except Exception as e:\n",
    "    print(\"Looks like you already have a bucket of this name. That's good!\")\n",
    "\n",
    "framework_version = '1.2-2'\n",
    "docker_image_name = sagemaker.image_uris.retrieve(framework='xgboost', region=region, version=framework_version)\n",
    "\n",
    "# Workaround while versions are not updated in SM SDK\n",
    "framework_version = '1.3-1'\n",
    "docker_image_name = docker_image_name[:-5] + framework_version\n",
    "\n",
    "print(\"Setting some useful environment variables (bucket, prefix, region, docker_image_name)...\")\n",
    "%store bucket\n",
    "%store prefix\n",
    "%store region\n",
    "%store docker_image_name\n",
    "%store framework_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Let's download the data and upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://higheredbcs.wiley.com/legacy/college/larose/0470908742/ds/data_sets.zip\n",
    "!unzip -o data_sets.zip\n",
    "!mv \"Data sets\"/churn.txt .\n",
    "!rm -rf \"Data sets\" data_sets.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_raw_path = \"churn.txt\"\n",
    "raw_dir = f\"{prefix}/data/raw\"\n",
    "s3uri_raw = sagemaker.s3.S3Uploader.upload(local_raw_path, f's3://{bucket}/{raw_dir}')\n",
    "s3uri_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the raw data S3 URI for later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store s3uri_raw\n",
    "\n",
    "print(\"\\n\\nWe are ready for starting the SageMaker Workshop!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# [You can now go to the first lab 1-DataPrep](../1-DataPrep/data_preparation.ipynb)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
